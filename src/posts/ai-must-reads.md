---
title: "Must-Read AI Blog Posts: OpenAI + Google DeepMind"
date: 2025-12-30
tags: ["ai", "reading-list", "openai", "google-deepmind", "llms", "genai"]
description: "A curated, high-signal reading list of official OpenAI and Google DeepMind/Google AI posts (models, evals, safety, and developer tooling)."
---

# Must-Read AI Blog Posts: OpenAI + Google DeepMind

A “no fluff” list of official posts worth reading end-to-end.

## OpenAI (must-read)

1. [Evaluating chain-of-thought monitorability](https://openai.com/index/evaluating-chain-of-thought-monitorability/) (Dec 18, 2025)  
   - References: [Monitoring Monitorability (PDF)](https://cdn.openai.com/pdf/d57827c6-10bc-47fe-91aa-0fde55bd3901/monitoring-monitorability.pdf)

2. [Introducing gpt-oss](https://openai.com/index/introducing-gpt-oss/) (Aug 5, 2025)  
   - References: [gpt-oss Model Card](https://openai.com/index/gpt-oss-model-card/), [Model Card PDF](https://cdn.openai.com/pdf/419b6906-9da6-406c-a19d-1bb078ac7637/oai_gpt-oss_model_card.pdf), [Open models hub](https://openai.com/open-models/), [gpt-oss cookbook](https://cookbook.openai.com/topic/gpt-oss)

3. [Measuring the performance of our models on real-world tasks (GDPval)](https://openai.com/index/gdpval/) (Sep 25, 2025)  
   - References: [GDPval paper (PDF)](https://cdn.openai.com/pdf/d5eb7428-c4e9-4a33-bd86-86dd4bcf12ce/GDPval.pdf), [OpenAI Evals](https://evals.openai.com/)

4. [Learning to reason with LLMs](https://openai.com/index/learning-to-reason-with-llms/) (Sep 12, 2024)  
   - References: [OpenAI o1](https://openai.com/o1/), [OpenAI o1 System Card](https://openai.com/index/openai-o1-system-card/)

5. [Hello GPT-4o](https://openai.com/index/hello-gpt-4o/) (May 13, 2024)  
   - References: [GPT-4o System Card](https://openai.com/index/gpt-4o-system-card/)

6. [GPT-4o System Card](https://openai.com/index/gpt-4o-system-card/) (Aug 8, 2024)  
   - References: [PDF version](https://cdn.openai.com/gpt-4o-system-card.pdf)

7. [Introducing Structured Outputs in the API](https://openai.com/index/introducing-structured-outputs-in-the-api/) (Aug 6, 2024)  
   - References: [Structured Outputs intro (Cookbook)](https://cookbook.openai.com/examples/structured_outputs_intro)

8. [Introducing the Model Spec](https://openai.com/index/introducing-the-model-spec/) (May 8, 2024; updated Feb 12, 2025)  
   - References: [Model Spec (latest)](https://model-spec.openai.com/), [Model Spec (2025-02-12 snapshot)](https://model-spec.openai.com/2025-02-12.html)

9. [Function calling and other API updates](https://openai.com/index/function-calling-and-other-api-updates/) (Jun 13, 2023)

10. [Sora 2 is here](https://openai.com/index/sora-2/) (Sep 30, 2025)  
   - References: [Sora 2 System Card](https://openai.com/index/sora-2-system-card/), [System Card PDF](https://cdn.openai.com/pdf/50d5973c-c4ff-4c2d-986f-c72b5d0ff069/sora_2_system_card.pdf), [Video generation models as world simulators](https://openai.com/index/video-generation-models-as-world-simulators/)

## Google AI / Google DeepMind (must-read)

1. [Introducing Gemini 1.5, Google’s next-generation AI model](https://blog.google/technology/ai/google-gemini-next-generation-model-february-2024/) (Feb 15, 2024)

2. [What is a long context window?](https://blog.google/technology/ai/long-context-window-ai-models/) (Feb 16, 2024)

3. [Gemini breaks new ground with a faster model, longer context, AI agents and more](https://blog.google/technology/ai/google-gemini-update-flash-ai-assistant-io-2024/) (May 14, 2024)  
   - References: [Google I/O 2024 announcement collection](https://blog.google/technology/developers/google-io-2024-collection/)

4. [Gemma: Introducing new state-of-the-art open models](https://blog.google/technology/developers/gemma-open-models/) (Feb 21, 2024)

5. [Gemma 2 is now available to researchers and developers](https://blog.google/technology/developers/google-gemma-2/) (Jun 27, 2024)

6. [Genie 2: A large-scale foundation world model](https://deepmind.google/blog/genie-2-a-large-scale-foundation-world-model/) (Dec 4, 2024)

7. [Start building with Gemini 2.0 Flash and Flash-Lite](https://developers.googleblog.com/en/start-building-with-the-gemini-2-0-flash-family/) (Feb 25, 2025)  
   - References: [Gemini 2.0 is now available to everyone](https://blog.google/technology/google-deepmind/gemini-model-updates-february-2025/)

8. [Our vision for building a universal AI assistant](https://deepmind.google/blog/our-vision-for-building-a-universal-ai-assistant/) (May 20, 2025)  
   - References: [Google I/O 2025 announcement collection](https://blog.google/technology/developers/google-io-2025-collection/)

9. [Gemini Robotics brings AI into the physical world](https://deepmind.google/blog/gemini-robotics-brings-ai-into-the-physical-world/) (Mar 12, 2025)

10. [FunSearch: Making new discoveries in mathematical sciences using Large Language Models](https://deepmind.google/blog/funsearch-making-new-discoveries-in-mathematical-sciences-using-large-language-models/) (Dec 14, 2023)  
   - References: [Paper (PDF)](https://storage.googleapis.com/deepmind-media/DeepMind.com/Blog/funsearch-making-new-discoveries-in-mathematical-sciences-using-large-language-models/Mathematical-discoveries-from-program-search-with-large-language-models.pdf), [Nature article](https://www.nature.com/articles/s41586-023-06924-6)
